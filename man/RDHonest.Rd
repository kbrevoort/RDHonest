% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RDHonest.R
\name{RDHonest}
\alias{RDHonest}
\title{Honest inference in RD}
\usage{
RDHonest(
  formula,
  data,
  subset,
  weights,
  cutoff = 0,
  M,
  kern = "triangular",
  na.action,
  opt.criterion = "MSE",
  h,
  se.method = "nn",
  alpha = 0.05,
  beta = 0.8,
  J = 3,
  sclass = "H",
  T0 = 0,
  point.inference = FALSE
)
}
\arguments{
\item{formula}{object of class \code{"formula"} (or one that can be coerced
to that class) of the form \code{outcome ~ running_variable}}

\item{data}{optional data frame, list or environment (or object coercible by
\code{as.data.frame} to a data frame) containing the outcome and running
variables in the model. If not found in \code{data}, the variables are
taken from \code{environment(formula)}, typically the environment from
which the function is called.}

\item{subset}{optional vector specifying a subset of observations to be used
in the fitting process.}

\item{weights}{Optional vector of weights to weight the observations
(useful for aggregated data). Disregarded if optimal kernel is used.}

\item{cutoff}{specifies the RD cutoff in the running variable. For inference
at a point, specified the point \eqn{x_0} at which to calculate the
conditional mean.}

\item{M}{Bound on second derivative of the conditional mean function.}

\item{kern}{specifies kernel function used in the local regression. It can
either be a string equal to \code{"triangular"} (\eqn{k(u)=(1-|u|)_{+}}),
\code{"epanechnikov"} (\eqn{k(u)=(3/4)(1-u^2)_{+}}), or \code{"uniform"}
(\eqn{k(u)= (|u|<1)/2}), or else a kernel function.}

\item{na.action}{function which indicates what should happen when the data
contain \code{NA}s. The default is set by the \code{na.action} setting of
\code{options} (usually \code{na.omit}). Another possible value is
\code{na.fail}}

\item{opt.criterion}{Optimality criterion that bandwidth is designed to
    optimize. The options are:

   \describe{

   \item{\code{"MSE"}}{Finite-sample maximum MSE}

   \item{\code{"FLCI"}}{Length of (fixed-length) two-sided
       confidence intervals.}

   \item{\code{"OCI"}}{Given quantile of excess length of one-sided
       confidence intervals}

    }

    The methods use conditional variance given by \code{sigma2}, if supplied.
    Otherwise, for the purpose of estimating the optimal bandwidth,
    conditional variance is estimated using the method specified by
    \code{se.initial}.}

\item{h}{bandwidth, a scalar parameter. If not supplied, optimal bandwidth is
computed according to criterion given by \code{opt.criterion}.}

\item{se.method}{Vector with methods for estimating standard error of
estimate. If \code{NULL}, standard errors are not computed. The elements of
the vector can consist of the following methods:

\describe{
    \item{"nn"}{Nearest neighbor method}

    \item{"EHW"}{Eicker-Huber-White, with residuals from local regression
    (local polynomial estimators only).}

   \item{"supplied.var"}{Use conditional variance supplied by \code{sigma2} or
        \code{d} instead of computing residuals}

}}

\item{alpha}{determines confidence level, \code{1-alpha} for
constructing/optimizing confidence intervals.}

\item{beta}{Determines quantile of excess length to optimize, if bandwidth
optimizes given quantile of excess length of one-sided confidence
intervals; otherwise ignored.}

\item{J}{Number of nearest neighbors, if "nn" is specified in
\code{se.method}.}

\item{sclass}{Smoothness class, either \code{"T"} for Taylor or
\code{"H"} for Hölder class.}

\item{T0}{Initial estimate of the treatment effect for calculating the
optimal bandwidth. Only relevant for Fuzzy RD.}

\item{point.inference}{Do inference at a point determined by \code{cutoff}
instead of RD.}
}
\value{
Returns an object of class \code{"NPRResults"}. The function
    \code{print} can be used to obtain and print a summary of the results. An
    object of class \code{"NPRResults"} is a list containing the following
    components

    \describe{
  \item{\code{estimate}}{Point estimate. This estimate is MSE-optimal if
                  \code{opt.criterion="MSE"}}

  \item{\code{lff}}{Least favorable function, only relevant for optimal
             estimator under Taylor class.}

  \item{\code{maxbias}}{Maximum bias of \code{estimate}}

  \item{\code{sd}}{Standard deviation of estimate}

  \item{\code{lower}, \code{upper}}{Lower (upper) end-point of a one-sided CI
        based on \code{estimate}. This CI is optimal if
        \code{opt.criterion=="OCI"}}

  \item{\code{hl}}{Half-length of a two-sided CI based on \code{estimate}, so
            that the CI is given by \code{c(estimate-hl, estimate+hl)}. The
            CI is optimal if \code{opt.criterion="FLCI"}}

  \item{\code{eff.obs}}{Effective number of observations used by
            \code{estimate}}

  \item{\code{h}}{Bandwidth used}

  \item{\code{naive}}{Coverage of CI that ignores bias and uses
               \code{qnorm(1-alpha/2)} as critical value}

  \item{\code{call}}{the matched call}

  \item{\code{fs}}{Estimate of the first-stage coefficient (sharp RD only)}

}
}
\description{
Calculate estimators and bias-aware CIs for the sharp or fuzzy RD parameter,
or for value of the conditional mean at a point.
}
\details{
The bandwidth is calculated to be optimal for a given performance criterion,
as specified by \code{opt.criterion}. Alternatively, for local polynomial
estimators, the bandwidth can be specified by \code{h}. For
\code{kern="optimal"}, calculate optimal estimators under second-order Taylor
smoothness class (sharp RD only).
}
\section{Note}{

\code{subset} is evaluated in the same way as variables in \code{formula},
that is first in \code{data} and then in the environment of \code{formula}.
}

\examples{

# Lee dataset
RDHonest(voteshare ~ margin, data = lee08, kern = "uniform", M = 0.1, h = 10)
RDHonest(cn~retired | elig_year, data=rcp, cutoff=0, M=c(4, 0.4),
          kern="triangular", opt.criterion="MSE", T0=0, h=3)
RDHonest(voteshare ~ margin, data = lee08, subset = margin>0,
          kern = "uniform", M = 0.1, h = 10, point.inference=TRUE)
}
\references{
{

\cite{Armstrong, Timothy B., and Michal Kolesár. 2018.
"Optimal Inference in a Class of Regression Models." Econometrica 86 (2):
655–83.}

\cite{Armstrong, Timothy B., and Michal Kolesár. 2020.
"Simple and Honest Confidence Intervals in Nonparametric Regression."
Quantitative Economics 11 (1): 1–39.}

\cite{Imbens, Guido, and Kalyanaraman, Karthik,
"Optimal bandwidth choice for the regression discontinuity estimator." The
Review of Economic Studies 79 (3): 933-959.}

\cite{Kolesár, Michal, and Christoph Rothe. 2018. "Inference in Regression
Discontinuity Designs with a Discrete Running Variable." American Economic
Review 108 (8): 2277–2304.}
}
}
